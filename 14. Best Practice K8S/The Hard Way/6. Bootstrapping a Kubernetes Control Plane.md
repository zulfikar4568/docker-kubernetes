# Bootstrapping a Kubernetes Control Plane

In order to configure a Kubernetes cluster, we need to be able to set up a Kubernetes control plane. The control plane manages the Kubernetes cluster and serves as its primary interface.

In this hands-on lab, we're going to set up a distributed Kubernetes control plane using two servers.

To do this, we will install and configure the following services:

kube-apiserver
kube-controller-manager
kube-scheduler
kubectl

Objective:
- Download and install the binaries.
- Configure the kube-apiserver service.
- Configure the kube-controller-manager service.
- Configure the kube-scheduler service.
- Successfully start all of the services.
- Enable HTTP health checks.
- Set up RBAC for kubelet authorization.


## Download and Install the Binaries
Complete the following steps in both of your terminal windows:

1. Create the /etc/kubernetes/config directory:
```bash
sudo mkdir -p /etc/kubernetes/config
```
2. Enter your cloud_user password at the prompt.

3. Download the service binaries:
```bash
wget -q --show-progress --https-only --timestamping \
  "https://storage.googleapis.com/kubernetes-release/release/v1.10.2/bin/linux/amd64/kube-apiserver" \
  "https://storage.googleapis.com/kubernetes-release/release/v1.10.2/bin/linux/amd64/kube-controller-manager" \
  "https://storage.googleapis.com/kubernetes-release/release/v1.10.2/bin/linux/amd64/kube-scheduler" \
  "https://storage.googleapis.com/kubernetes-release/release/v1.10.2/bin/linux/amd64/kubectl"
```
4. Run the following command to make the binaries executable:
```bash
chmod +x kube-apiserver kube-controller-manager kube-scheduler kubectl
```
5. Move the files we just downloaded to the /usr/local/bin directory:
```bash
sudo mv kube-apiserver kube-controller-manager kube-scheduler kubectl /usr/local/bin/
```
## Configure the kube-apiserver Service
Complete the following steps in both of your terminal windows:

1. Create the /var/lib/kubernetes directory:
```bash
sudo mkdir -p /var/lib/kubernetes/
```
2. List the contents of the home directory to view the certificate and kubeconfig files we need to set up our Kubernetes control plane:
```bash
ls
```
3. Move all the .pem files and the encryption-config.yaml file to the /var/lib/kubernetes directory:
```bash
sudo cp ca.pem ca-key.pem kubernetes-key.pem kubernetes.pem \
  service-account-key.pem service-account.pem \
  encryption-config.yaml /var/lib/kubernetes/
```
4. Set the INTERNAL_IP environment variable:
```bash
INTERNAL_IP=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
```
5. Set the following environment variables (be sure to replace the placeholders with the actual private IPs):
```bash
ETCD_SERVER_0=<CONTROLLER_0_PRIVATE_IP>
ETCD_SERVER_1=<CONTROLLER_1_PRIVATE_IP>
```
6. Create the systemd unit file for kube-apiserver:
```bash
cat << EOF | sudo tee /etc/systemd/system/kube-apiserver.service
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-apiserver \\
  --advertise-address=${INTERNAL_IP} \\
  --allow-privileged=true \\
  --apiserver-count=3 \\
  --audit-log-maxage=30 \\
  --audit-log-maxbackup=3 \\
  --audit-log-maxsize=100 \\
  --audit-log-path=/var/log/audit.log \\
  --authorization-mode=Node,RBAC \\
  --bind-address=0.0.0.0 \\
  --client-ca-file=/var/lib/kubernetes/ca.pem \\
  --enable-admission-plugins=Initializers,NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\
  --enable-swagger-ui=true \\
  --etcd-cafile=/var/lib/kubernetes/ca.pem \\
  --etcd-certfile=/var/lib/kubernetes/kubernetes.pem \\
  --etcd-keyfile=/var/lib/kubernetes/kubernetes-key.pem \\
  --etcd-servers=https://${ETCD_SERVER_0}:2379,https://${ETCD_SERVER_1}:2379 \\
  --event-ttl=1h \\
  --experimental-encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \\
  --kubelet-certificate-authority=/var/lib/kubernetes/ca.pem \\
  --kubelet-client-certificate=/var/lib/kubernetes/kubernetes.pem \\
  --kubelet-client-key=/var/lib/kubernetes/kubernetes-key.pem \\
  --kubelet-https=true \\
  --runtime-config=api/all \\
  --service-account-key-file=/var/lib/kubernetes/service-account.pem \\
  --service-cluster-ip-range=10.32.0.0/24 \\
  --service-node-port-range=30000-32767 \\
  --tls-cert-file=/var/lib/kubernetes/kubernetes.pem \\
  --tls-private-key-file=/var/lib/kubernetes/kubernetes-key.pem \\
  --v=2 \\
  --kubelet-preferred-address-types=InternalIP,InternalDNS,Hostname,ExternalIP,ExternalDNS
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
```
## Configure the kube-controller-manager Service
Complete the following steps in both of your terminal windows:

1. Move the kube-controller-manager.kubeconfig file to the /var/lib/kubernetes directory:
```bash
sudo mv kube-controller-manager.kubeconfig /var/lib/kubernetes/
```
2. Create the systemd unit control file for kube-controller-manager:
```bash
cat << EOF | sudo tee /etc/systemd/system/kube-controller-manager.service
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-controller-manager \\
  --address=0.0.0.0 \\
  --cluster-cidr=10.200.0.0/16 \\
  --cluster-name=kubernetes \\
  --cluster-signing-cert-file=/var/lib/kubernetes/ca.pem \\
  --cluster-signing-key-file=/var/lib/kubernetes/ca-key.pem \\
  --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\
  --leader-elect=true \\
  --root-ca-file=/var/lib/kubernetes/ca.pem \\
  --service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem \\
  --service-cluster-ip-range=10.32.0.0/24 \\
  --use-service-account-credentials=true \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
```
## Configure the kube-scheduler Service
Complete the following steps in both of your terminal windows:

1. Move the kube-scheduler.kubeconfig file to the /var/lib/kubernetes directory:
```bash
sudo mv kube-scheduler.kubeconfig /var/lib/kubernetes/
```
2. Create the kube-scheduler config file:
```bash
cat << EOF | sudo tee /etc/kubernetes/config/kube-scheduler.yaml
apiVersion: componentconfig/v1alpha1
kind: KubeSchedulerConfiguration
clientConnection:
  kubeconfig: "/var/lib/kubernetes/kube-scheduler.kubeconfig"
leaderElection:
  leaderElect: true
EOF
```
3. Create the systemd unit file for kube-scheduler:
```bash
cat << EOF | sudo tee /etc/systemd/system/kube-scheduler.service
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-scheduler \\
  --config=/etc/kubernetes/config/kube-scheduler.yaml \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
```

## Start All of the Services
Complete the following steps in both of your terminal windows:

1. Enable and start the Kubernetes control plane services:
```bash
sudo systemctl daemon-reload

sudo systemctl enable kube-apiserver kube-controller-manager kube-scheduler

sudo systemctl start kube-apiserver kube-controller-manager kube-scheduler
```
2. Run the following command to verify everything is working properly:
```bash
kubectl get componentstatuses --kubeconfig admin.kubeconfig
```
The output should look something like this:
```
NAME                 STATUS    MESSAGE              ERROR
controller-manager   Healthy   ok
scheduler            Healthy   ok
etcd-0               Healthy   {"health": "true"}
etcd-1               Healthy   {"health": "true"}
```
## Enable HTTP Health Checks
Complete the following steps in both of your terminal windows:

1. Install Nginx:
```bash
sudo apt-get install -y nginx
```
2. Create an Nginx config file:
```bash
cat > kubernetes.default.svc.cluster.local << EOF
server {
  listen      80;
  server_name kubernetes.default.svc.cluster.local;

  location /healthz {
     proxy_pass                    https://127.0.0.1:6443/healthz;
     proxy_ssl_trusted_certificate /var/lib/kubernetes/ca.pem;
  }
}
EOF
```
3. Move the Nginx config file to the /etc/nginx/sites-available directory:
```bash
sudo mv kubernetes.default.svc.cluster.local \
  /etc/nginx/sites-available/kubernetes.default.svc.cluster.local
```
4. Create a symlink in the /sites-enabled directory:
```bash
sudo ln -s /etc/nginx/sites-available/kubernetes.default.svc.cluster.local /etc/nginx/sites-enabled/
```
5. Start and enable Nginx:
```bash
sudo systemctl restart nginx

sudo systemctl enable nginx
```
6. Verify the HTTP health checks are working:
```bash
curl -H "Host: kubernetes.default.svc.cluster.local" -i http://127.0.0.1/healthz
```
This should return a 200 OK status code.

## Set Up RBAC for Kubelet Authorization
Complete the following steps in one of your terminal windows:

Note: It's okay if you complete these steps in both of your terminal windows â€” the lab will still work. It just isn't a requirement to do so.

1. Create a cluster role to allow the kubernetes-apiservice to access the kubelets:
```bash
cat << EOF | kubectl apply --kubeconfig admin.kubeconfig -f -
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:kube-apiserver-to-kubelet
rules:
  - apiGroups:
      - ""
    resources:
      - nodes/proxy
      - nodes/stats
      - nodes/log
      - nodes/spec
      - nodes/metrics
    verbs:
      - "*"
EOF
```
2. Assign the role to the kube-apiserver user:
```bash
cat << EOF | kubectl apply --kubeconfig admin.kubeconfig -f -
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: system:kube-apiserver
  namespace: ""
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:kube-apiserver-to-kubelet
subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: kubernetes
EOF
```